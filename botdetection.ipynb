{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797162b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\omgha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.layers import GRU, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d42a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8278\n",
      "Testing samples: 1183\n",
      "Dev samples: 2365\n",
      "Columns: ['ID', 'profile', 'tweet', 'neighbor', 'domain', 'label']\n",
      "Label distribution in training set: label\n",
      "1    4646\n",
      "0    3632\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in training set:\n",
      "ID            0\n",
      "profile       0\n",
      "tweet        55\n",
      "neighbor    754\n",
      "domain        0\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load Twibot-20 dataset with the structure you described\n",
    "def load_twibot20(data_path):\n",
    "    train_data = pd.read_json(os.path.join(data_path, 'train.json'))\n",
    "    test_data = pd.read_json(os.path.join(data_path, 'test.json'))\n",
    "    dev_data = pd.read_json(os.path.join(data_path, 'dev.json'))\n",
    "    \n",
    "    return train_data, test_data, dev_data\n",
    "\n",
    "# Load the data\n",
    "train_data, test_data, dev_data = load_twibot20('data')\n",
    "\n",
    "# Check dataset structure\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Testing samples: {len(test_data)}\")\n",
    "print(f\"Dev samples: {len(dev_data)}\")\n",
    "print(f\"Columns: {train_data.columns.tolist()}\")\n",
    "\n",
    "# Check label distribution\n",
    "label_counts = train_data['label'].value_counts()\n",
    "print(\"Label distribution in training set:\", label_counts)\n",
    "\n",
    "# Visualize label distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=train_data)\n",
    "plt.title('Distribution of Labels in Twibot-20 Training Set')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training set:\")\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "664b86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess tweet text with better handling of edge cases\"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str) or text.strip() == '':\n",
    "        return \"empty_text\"  # Use a placeholder instead of empty string\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Check for empty result\n",
    "    if not text.strip():\n",
    "        return \"empty_text\"\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53ded11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_df(df):\n",
    "    \"\"\"Extract features with better error handling and data validation\"\"\"\n",
    "    tweet_texts = []\n",
    "    metadata_features = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\"):\n",
    "        # Process tweets\n",
    "        tweets = []\n",
    "        try:\n",
    "            tweet_value = row['tweet']\n",
    "            if isinstance(tweet_value, str) and not pd.isna(tweet_value):\n",
    "                try:\n",
    "                    tweet_data = json.loads(tweet_value.replace(\"'\", \"\\\"\"))\n",
    "                    if isinstance(tweet_data, list):\n",
    "                        for tweet in tweet_data:\n",
    "                            if isinstance(tweet, dict) and 'text' in tweet:\n",
    "                                tweets.append(preprocess_text(tweet['text']))\n",
    "                except:\n",
    "                    tweets.append(preprocess_text(tweet_value))\n",
    "        except (KeyError, TypeError):\n",
    "            pass  # Handle case where 'tweet' column doesn't exist\n",
    "        \n",
    "        # Add placeholder for empty tweets\n",
    "        if not tweets:\n",
    "            tweets = [\"empty_text\"]\n",
    "        \n",
    "        # Process profile with better error handling\n",
    "        followers = 0\n",
    "        friends = 0\n",
    "        verified = 0\n",
    "        has_profile_pic = 0\n",
    "        statuses_count = 0\n",
    "        desc_length = 0\n",
    "        \n",
    "        try:\n",
    "            profile_value = row['profile']\n",
    "            if isinstance(profile_value, str) and not pd.isna(profile_value):\n",
    "                try:\n",
    "                    profile = json.loads(profile_value.replace(\"'\", \"\\\"\"))\n",
    "                    if isinstance(profile, dict):\n",
    "                        followers = int(float(profile.get('followers_count', 0)))\n",
    "                        friends = int(float(profile.get('friends_count', 0)))\n",
    "                        verified = 1 if profile.get('verified', False) else 0\n",
    "                        has_profile_pic = 0 if profile.get('default_profile_image', True) else 1\n",
    "                        statuses_count = int(float(profile.get('statuses_count', 0)))\n",
    "                        desc_length = len(str(profile.get('description', '')))\n",
    "                except (ValueError, TypeError):\n",
    "                    pass  # Use default values if conversion fails\n",
    "        except (KeyError, TypeError):\n",
    "            pass  # Handle case where 'profile' column doesn't exist\n",
    "            \n",
    "        # Calculate ff_ratio safely with upper bound\n",
    "        ff_ratio = 0\n",
    "        if friends > 0:\n",
    "            ff_ratio = min(followers / max(friends, 1), 100)  # Cap ratio at 100\n",
    "            \n",
    "        # Create metadata feature vector with safety bounds\n",
    "        metadata = [\n",
    "            max(0, min(followers, 1e7)),        # Reasonable upper bound\n",
    "            max(0, min(friends, 1e6)),\n",
    "            ff_ratio,\n",
    "            max(0, min(statuses_count, 1e6)),\n",
    "            verified,\n",
    "            has_profile_pic,\n",
    "            max(0, min(desc_length, 5000))\n",
    "        ]\n",
    "        \n",
    "        tweet_texts.append(\" \".join(tweets))\n",
    "        metadata_features.append(metadata)\n",
    "    \n",
    "    # Final validation of metadata features\n",
    "    metadata_array = np.array(metadata_features, dtype=np.float32)\n",
    "    \n",
    "    # Replace infinities and NaNs\n",
    "    metadata_array = np.nan_to_num(metadata_array, nan=0.0, posinf=100.0, neginf=0.0)\n",
    "    \n",
    "    return tweet_texts, metadata_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b31929f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_integrity(features, name=\"dataset\"):\n",
    "    \"\"\"Check for anomalies in extracted features\"\"\"\n",
    "    print(f\"\\n--- Data integrity check for {name} ---\")\n",
    "    print(f\"Shape: {features.shape}\")\n",
    "    print(f\"NaN values: {np.isnan(features).sum()}\")\n",
    "    print(f\"Inf values: {np.isinf(features).sum()}\")\n",
    "    print(f\"Min values: {features.min(axis=0)}\")\n",
    "    print(f\"Max values: {features.max(axis=0)}\")\n",
    "    print(f\"Mean values: {features.mean(axis=0)}\")\n",
    "    print(\"-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03fe3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Improved model architecture with regularization\n",
    "def build_better_model(vocab_size,max_length, embed_dim=128, rnn_units=64, metadata_dim=7):\n",
    "    \"\"\"Build a more stable model with regularization and batch normalization\"\"\"\n",
    "    # Text input branch\n",
    "    text_input = Input(shape=(max_length,), name='text_input')\n",
    "    emb = Embedding(vocab_size, embed_dim, mask_zero=True)(text_input)\n",
    "    \n",
    "    # Use GRU with gradient clipping built-in\n",
    "    rnn = Bidirectional(GRU(rnn_units, \n",
    "                            recurrent_initializer='glorot_uniform',\n",
    "                            recurrent_activation='sigmoid',\n",
    "                            reset_after=True))(emb)\n",
    "    \n",
    "    # Add regularization\n",
    "    x = BatchNormalization()(rnn)\n",
    "    x = Dropout(0.3)(x)\n",
    "    text_features = Dense(32, activation='relu', \n",
    "                         kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    \n",
    "    # Metadata input branch with preprocessing\n",
    "    meta_input = Input(shape=(metadata_dim,), name='meta_input')\n",
    "    m = BatchNormalization()(meta_input)  # Normalize inputs\n",
    "    meta_features = Dense(16, activation='relu',\n",
    "                         kernel_regularizer=tf.keras.regularizers.l2(0.001))(m)\n",
    "    \n",
    "    # Combine features\n",
    "    combined = Concatenate()([text_features, meta_features])\n",
    "    x = BatchNormalization()(combined)\n",
    "    x = Dense(32, activation='relu',\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[text_input, meta_input], outputs=output)\n",
    "    \n",
    "    # Use a small learning rate with gradient clipping\n",
    "    optimizer = Adam(learning_rate=5e-5, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \n",
    "                tf.keras.metrics.Precision(), \n",
    "                tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6eda804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Custom callback to check for NaN values\n",
    "class NanMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(f\"\\nBatch {batch}: Invalid loss, terminating training\")\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        # Check if metrics contain NaNs\n",
    "        for metric, value in logs.items():\n",
    "            if np.isnan(value) or np.isinf(value):\n",
    "                print(f\"\\nEpoch {epoch}: NaN in {metric}, terminating training\")\n",
    "                self.model.stop_training = True\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2c124ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Main execution function\n",
    "def train_and_evaluate_model(train_data, test_data, dev_data):\n",
    "    \"\"\"Train and evaluate the bot detection model with proper error handling\"\"\"\n",
    "    # Extract features\n",
    "    print(\"Extracting features from training data...\")\n",
    "    train_texts, train_metadata = extract_features_from_df(train_data)\n",
    "    print(\"Extracting features from test data...\")\n",
    "    test_texts, test_metadata = extract_features_from_df(test_data)\n",
    "    print(\"Extracting features from dev data...\")\n",
    "    dev_texts, dev_metadata = extract_features_from_df(dev_data)\n",
    "    \n",
    "    # Check metadata feature integrity\n",
    "    check_data_integrity(train_metadata, \"training metadata\")\n",
    "    check_data_integrity(test_metadata, \"test metadata\")\n",
    "    \n",
    "    # Using sklearn's LabelEncoder\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(train_data['label'])\n",
    "    y_test = label_encoder.transform(test_data['label'])\n",
    "    y_dev = label_encoder.transform(dev_data['label'])\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(f\"Training class distribution: {np.bincount(y_train.astype(int))}\")\n",
    "    print(f\"Test class distribution: {np.bincount(y_test.astype(int))}\")\n",
    "    print(f\"Dev class distribution: {np.bincount(y_dev.astype(int))}\")\n",
    "    \n",
    "    # Tokenize text data\n",
    "    max_words = 10000\n",
    "    max_length = 100\n",
    "    \n",
    "    # Add special tokens\n",
    "    tokenizer = Tokenizer(num_words=max_words, oov_token=\"<UNK>\")\n",
    "    \n",
    "    # Include empty_text placeholder in vocabulary\n",
    "    all_texts = train_texts + [\"empty_text\"]  \n",
    "    tokenizer.fit_on_texts(all_texts)\n",
    "    \n",
    "    # Convert text to sequences\n",
    "    X_train_text = tokenizer.texts_to_sequences(train_texts)\n",
    "    X_test_text = tokenizer.texts_to_sequences(test_texts)\n",
    "    X_dev_text = tokenizer.texts_to_sequences(dev_texts)\n",
    "    \n",
    "    # Pad sequences\n",
    "    X_train_text_pad = pad_sequences(X_train_text, maxlen=max_length)\n",
    "    X_test_text_pad = pad_sequences(X_test_text, maxlen=max_length)\n",
    "    X_dev_text_pad = pad_sequences(X_dev_text, maxlen=max_length)\n",
    "    \n",
    "    # Robust scaling of metadata\n",
    "    scaler = RobustScaler()\n",
    "    X_train_meta = scaler.fit_transform(train_metadata)\n",
    "    X_test_meta = scaler.transform(test_metadata)\n",
    "    X_dev_meta = scaler.transform(dev_metadata)\n",
    "    \n",
    "    # Final cleanup of metadata\n",
    "    X_train_meta = np.nan_to_num(X_train_meta, nan=0.0)\n",
    "    X_test_meta = np.nan_to_num(X_test_meta, nan=0.0)\n",
    "    X_dev_meta = np.nan_to_num(X_dev_meta, nan=0.0)\n",
    "    \n",
    "    # Clip extreme values\n",
    "    X_train_meta = np.clip(X_train_meta, -10, 10)\n",
    "    X_test_meta = np.clip(X_test_meta, -10, 10)\n",
    "    X_dev_meta = np.clip(X_dev_meta, -10, 10)\n",
    "    \n",
    "    print(f\"Training text shape: {X_train_text_pad.shape}\")\n",
    "    print(f\"Training metadata shape: {X_train_meta.shape}\")\n",
    "    print(f\"Test text shape: {X_test_text_pad.shape}\")\n",
    "    print(f\"Test metadata shape: {X_test_meta.shape}\")\n",
    "    \n",
    "    # Create model\n",
    "    vocab_size = min(len(tokenizer.word_index) + 1, max_words)\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "    \n",
    "    model = build_better_model(vocab_size, max_length, metadata_dim=X_train_meta.shape[1])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Set up callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=5, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        'bot_detector_best.h5', \n",
    "        save_best_only=True, \n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    nan_monitor = NanMonitor()\n",
    "    \n",
    "    # Handle class imbalance\n",
    "    class_weight = {\n",
    "        0: 1.0, \n",
    "        1: len(y_train[y_train == 0]) / max(1, len(y_train[y_train == 1]))\n",
    "    }\n",
    "    print(f\"Using class weights: {class_weight}\")\n",
    "    \n",
    "    # Train with small batch size initially\n",
    "    print(\"\\nStarting training with small batch size...\")\n",
    "    history = model.fit(\n",
    "        [X_train_text_pad, X_train_meta], y_train,\n",
    "        validation_data=([X_dev_text_pad, X_dev_meta], y_dev),\n",
    "        epochs=3,\n",
    "        batch_size=16,  # Very small batch size\n",
    "        callbacks=[early_stopping, model_checkpoint, reduce_lr, nan_monitor],\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    \n",
    "    # If initial training works, continue with larger batch size\n",
    "    if not np.isnan(history.history['loss'][-1]):\n",
    "        print(\"\\nContinuing training with larger batch size...\")\n",
    "        history = model.fit(\n",
    "            [X_train_text_pad, X_train_meta], y_train,\n",
    "            validation_data=([X_dev_text_pad, X_dev_meta], y_dev),\n",
    "            initial_epoch=len(history.history['loss']),\n",
    "            epochs=50,\n",
    "            batch_size=42,\n",
    "            callbacks=[early_stopping, model_checkpoint, reduce_lr, nan_monitor],\n",
    "            class_weight=class_weight\n",
    "        )\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    results = model.evaluate([X_test_text_pad, X_test_meta], y_test)\n",
    "    print(f\"Test Loss: {results[0]:.4f}\")\n",
    "    print(f\"Test Accuracy: {results[1]:.4f}\")\n",
    "    \n",
    "    # Get precision and recall\n",
    "    precision = results[2]\n",
    "    recall = results[3]\n",
    "    \n",
    "    # Safe F1 calculation\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    \n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Alternative evaluation using scikit-learn\n",
    "    print(\"\\nEvaluating with raw predictions...\")\n",
    "    y_pred_prob = model.predict([X_test_text_pad, X_test_meta])\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    sk_precision = precision_score(y_test, y_pred)\n",
    "    sk_recall = recall_score(y_test, y_pred)\n",
    "    sk_f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Sklearn Precision: {sk_precision:.4f}\")\n",
    "    print(f\"Sklearn Recall: {sk_recall:.4f}\")\n",
    "    print(f\"Sklearn F1-Score: {sk_f1:.4f}\")\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b58b96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 8278/8278 [00:00<00:00, 25458.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 1183/1183 [00:00<00:00, 15942.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from dev data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 2365/2365 [00:00<00:00, 25088.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data integrity check for training metadata ---\n",
      "Shape: (8278, 7)\n",
      "NaN values: 0\n",
      "Inf values: 0\n",
      "Min values: [0. 0. 0. 0. 0. 0. 0.]\n",
      "Max values: [0. 0. 0. 0. 0. 0. 0.]\n",
      "Mean values: [0. 0. 0. 0. 0. 0. 0.]\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "--- Data integrity check for test metadata ---\n",
      "Shape: (1183, 7)\n",
      "NaN values: 0\n",
      "Inf values: 0\n",
      "Min values: [0. 0. 0. 0. 0. 0. 0.]\n",
      "Max values: [0. 0. 0. 0. 0. 0. 0.]\n",
      "Mean values: [0. 0. 0. 0. 0. 0. 0.]\n",
      "-------------------------------------\n",
      "\n",
      "Training class distribution: [3632 4646]\n",
      "Test class distribution: [543 640]\n",
      "Dev class distribution: [1062 1303]\n",
      "Training text shape: (8278, 100)\n",
      "Training metadata shape: (8278, 7)\n",
      "Test text shape: (1183, 100)\n",
      "Test metadata shape: (1183, 7)\n",
      "Vocabulary size: 4\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " text_input (InputLayer)     [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 100, 128)             512       ['text_input[0][0]']          \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 128)                  74496     ['embedding_1[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128)                  512       ['bidirectional_1[0][0]']     \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " meta_input (InputLayer)     [(None, 7)]                  0         []                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 7)                    28        ['meta_input[0][0]']          \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 32)                   4128      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 16)                   128       ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 48)                   0         ['dense_4[0][0]',             \n",
      " )                                                                   'dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 48)                   192       ['concatenate_1[0][0]']       \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 32)                   1568      ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 32)                   0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1)                    33        ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 81597 (318.74 KB)\n",
      "Trainable params: 81231 (317.31 KB)\n",
      "Non-trainable params: 366 (1.43 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Using class weights: {0: 1.0, 1: 0.7817477399913905}\n",
      "\n",
      "Starting training with small batch size...\n",
      "Epoch 1/3\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.6917 - accuracy: 0.5093 - precision_1: 0.5585 - recall_1: 0.6005\n",
      "Epoch 1: val_loss improved from inf to 0.76342, saving model to bot_detector_best.h5\n",
      "518/518 [==============================] - 28s 39ms/step - loss: 0.6917 - accuracy: 0.5093 - precision_1: 0.5584 - recall_1: 0.6007 - val_loss: 0.7634 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 2/3\n",
      "  1/518 [..............................] - ETA: 16s - loss: 0.6686 - accuracy: 0.5625 - precision_1: 1.0000 - recall_1: 0.3000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omgha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/518 [============================>.] - ETA: 0s - loss: 0.6692 - accuracy: 0.4520 - precision_1: 0.5506 - recall_1: 0.1311\n",
      "Epoch 2: val_loss improved from 0.76342 to 0.76055, saving model to bot_detector_best.h5\n",
      "518/518 [==============================] - 18s 34ms/step - loss: 0.6692 - accuracy: 0.4522 - precision_1: 0.5501 - recall_1: 0.1311 - val_loss: 0.7605 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 3/3\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.6545 - accuracy: 0.4808 - precision_1: 0.5689 - recall_1: 0.3093\n",
      "Epoch 3: val_loss improved from 0.76055 to 0.73732, saving model to bot_detector_best.h5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.6545 - accuracy: 0.4807 - precision_1: 0.5687 - recall_1: 0.3091 - val_loss: 0.7373 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "\n",
      "Continuing training with larger batch size...\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6467 - accuracy: 0.4757 - precision_1: 0.5589 - recall_1: 0.3125\n",
      "Epoch 4: val_loss improved from 0.73732 to 0.72648, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 43ms/step - loss: 0.6467 - accuracy: 0.4757 - precision_1: 0.5589 - recall_1: 0.3125 - val_loss: 0.7265 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.4694 - precision_1: 0.5543 - recall_1: 0.2792\n",
      "Epoch 5: val_loss did not improve from 0.72648\n",
      "198/198 [==============================] - 8s 42ms/step - loss: 0.6429 - accuracy: 0.4694 - precision_1: 0.5543 - recall_1: 0.2792 - val_loss: 0.7316 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6394 - accuracy: 0.4716 - precision_1: 0.5559 - recall_1: 0.2912\n",
      "Epoch 6: val_loss improved from 0.72648 to 0.72595, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 8s 41ms/step - loss: 0.6394 - accuracy: 0.4716 - precision_1: 0.5559 - recall_1: 0.2912 - val_loss: 0.7259 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 7/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6361 - accuracy: 0.4869 - precision_1: 0.5657 - recall_1: 0.3697\n",
      "Epoch 7: val_loss improved from 0.72595 to 0.71891, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 8s 43ms/step - loss: 0.6361 - accuracy: 0.4870 - precision_1: 0.5657 - recall_1: 0.3698 - val_loss: 0.7189 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 8/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6331 - accuracy: 0.4902 - precision_1: 0.5723 - recall_1: 0.3630\n",
      "Epoch 8: val_loss improved from 0.71891 to 0.71535, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 10s 49ms/step - loss: 0.6331 - accuracy: 0.4901 - precision_1: 0.5721 - recall_1: 0.3629 - val_loss: 0.7154 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.4721 - precision_1: 0.5507 - recall_1: 0.3226\n",
      "Epoch 9: val_loss improved from 0.71535 to 0.71428, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 10s 49ms/step - loss: 0.6306 - accuracy: 0.4721 - precision_1: 0.5507 - recall_1: 0.3226 - val_loss: 0.7143 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.4905 - precision_1: 0.5679 - recall_1: 0.3855\n",
      "Epoch 10: val_loss improved from 0.71428 to 0.70972, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 45ms/step - loss: 0.6281 - accuracy: 0.4905 - precision_1: 0.5679 - recall_1: 0.3855 - val_loss: 0.7097 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 11/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6259 - accuracy: 0.4873 - precision_1: 0.5611 - recall_1: 0.3957\n",
      "Epoch 11: val_loss did not improve from 0.70972\n",
      "198/198 [==============================] - 9s 45ms/step - loss: 0.6259 - accuracy: 0.4873 - precision_1: 0.5614 - recall_1: 0.3958 - val_loss: 0.7109 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 12/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6240 - accuracy: 0.4807 - precision_1: 0.5474 - recall_1: 0.4305\n",
      "Epoch 12: val_loss did not improve from 0.70972\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "198/198 [==============================] - 9s 45ms/step - loss: 0.6240 - accuracy: 0.4808 - precision_1: 0.5476 - recall_1: 0.4307 - val_loss: 0.7116 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-05\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.4983 - precision_1: 0.5678 - recall_1: 0.4443\n",
      "Epoch 13: val_loss improved from 0.70972 to 0.70709, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6226 - accuracy: 0.4983 - precision_1: 0.5678 - recall_1: 0.4443 - val_loss: 0.7071 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.4976 - precision_1: 0.5638 - recall_1: 0.4634\n",
      "Epoch 14: val_loss improved from 0.70709 to 0.70597, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6217 - accuracy: 0.4976 - precision_1: 0.5638 - recall_1: 0.4634 - val_loss: 0.7060 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 15/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6208 - accuracy: 0.4892 - precision_1: 0.5555 - recall_1: 0.4517\n",
      "Epoch 15: val_loss improved from 0.70597 to 0.70511, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6209 - accuracy: 0.4894 - precision_1: 0.5555 - recall_1: 0.4516 - val_loss: 0.7051 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 16/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.4931 - precision_1: 0.5558 - recall_1: 0.4818\n",
      "Epoch 16: val_loss improved from 0.70511 to 0.70466, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6201 - accuracy: 0.4930 - precision_1: 0.5557 - recall_1: 0.4817 - val_loss: 0.7047 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.5191 - precision_1: 0.5764 - recall_1: 0.5400\n",
      "Epoch 17: val_loss improved from 0.70466 to 0.70364, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6192 - accuracy: 0.5191 - precision_1: 0.5764 - recall_1: 0.5400 - val_loss: 0.7036 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 18/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6186 - accuracy: 0.4979 - precision_1: 0.5614 - recall_1: 0.4818\n",
      "Epoch 18: val_loss improved from 0.70364 to 0.70273, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 45ms/step - loss: 0.6186 - accuracy: 0.4978 - precision_1: 0.5613 - recall_1: 0.4817 - val_loss: 0.7027 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 19/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6178 - accuracy: 0.4996 - precision_1: 0.5588 - recall_1: 0.5176\n",
      "Epoch 19: val_loss did not improve from 0.70273\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6179 - accuracy: 0.4995 - precision_1: 0.5584 - recall_1: 0.5176 - val_loss: 0.7029 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 20/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6172 - accuracy: 0.4981 - precision_1: 0.5622 - recall_1: 0.4788\n",
      "Epoch 20: val_loss improved from 0.70273 to 0.70211, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 47ms/step - loss: 0.6173 - accuracy: 0.4981 - precision_1: 0.5620 - recall_1: 0.4787 - val_loss: 0.7021 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.4882 - precision_1: 0.5531 - recall_1: 0.4582\n",
      "Epoch 21: val_loss improved from 0.70211 to 0.70154, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6167 - accuracy: 0.4882 - precision_1: 0.5531 - recall_1: 0.4582 - val_loss: 0.7015 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6160 - accuracy: 0.5006 - precision_1: 0.5637 - recall_1: 0.4875\n",
      "Epoch 22: val_loss improved from 0.70154 to 0.70076, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6160 - accuracy: 0.5006 - precision_1: 0.5637 - recall_1: 0.4875 - val_loss: 0.7008 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.4914 - precision_1: 0.5543 - recall_1: 0.4789\n",
      "Epoch 23: val_loss improved from 0.70076 to 0.69941, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6156 - accuracy: 0.4914 - precision_1: 0.5543 - recall_1: 0.4789 - val_loss: 0.6994 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.4961 - precision_1: 0.5583 - recall_1: 0.4892\n",
      "Epoch 24: val_loss did not improve from 0.69941\n",
      "198/198 [==============================] - 9s 45ms/step - loss: 0.6150 - accuracy: 0.4961 - precision_1: 0.5583 - recall_1: 0.4892 - val_loss: 0.6997 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 25/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6145 - accuracy: 0.4961 - precision_1: 0.5619 - recall_1: 0.4643\n",
      "Epoch 25: val_loss improved from 0.69941 to 0.69923, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 10s 48ms/step - loss: 0.6145 - accuracy: 0.4961 - precision_1: 0.5619 - recall_1: 0.4643 - val_loss: 0.6992 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6141 - accuracy: 0.4972 - precision_1: 0.5613 - recall_1: 0.4772\n",
      "Epoch 26: val_loss improved from 0.69923 to 0.69815, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 10s 49ms/step - loss: 0.6141 - accuracy: 0.4972 - precision_1: 0.5613 - recall_1: 0.4772 - val_loss: 0.6981 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 27/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6136 - accuracy: 0.5120 - precision_1: 0.5687 - recall_1: 0.5386\n",
      "Epoch 27: val_loss improved from 0.69815 to 0.69707, saving model to bot_detector_best.h5\n",
      "198/198 [==============================] - 9s 46ms/step - loss: 0.6136 - accuracy: 0.5118 - precision_1: 0.5688 - recall_1: 0.5383 - val_loss: 0.6971 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 28/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6132 - accuracy: 0.5060 - precision_1: 0.5626 - recall_1: 0.5407\n",
      "Epoch 28: val_loss did not improve from 0.69707\n",
      "198/198 [==============================] - 9s 48ms/step - loss: 0.6133 - accuracy: 0.5060 - precision_1: 0.5623 - recall_1: 0.5407 - val_loss: 0.6980 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 2.5000e-05\n",
      "Epoch 29/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6129 - accuracy: 0.5059 - precision_1: 0.5662 - recall_1: 0.5111\n",
      "Epoch 29: val_loss did not improve from 0.69707\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "198/198 [==============================] - 12s 62ms/step - loss: 0.6129 - accuracy: 0.5060 - precision_1: 0.5664 - recall_1: 0.5114 - val_loss: 0.6976 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.5001 - precision_1: 0.5597 - recall_1: 0.5127\n",
      "Epoch 30: val_loss did not improve from 0.69707\n",
      "198/198 [==============================] - 10s 52ms/step - loss: 0.6127 - accuracy: 0.5001 - precision_1: 0.5597 - recall_1: 0.5127 - val_loss: 0.6973 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 1.2500e-05\n",
      "Epoch 31/50\n",
      "197/198 [============================>.] - ETA: 0s - loss: 0.6125 - accuracy: 0.5077 - precision_1: 0.5658 - recall_1: 0.5299\n",
      "Epoch 31: val_loss did not improve from 0.69707\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "198/198 [==============================] - 10s 48ms/step - loss: 0.6125 - accuracy: 0.5076 - precision_1: 0.5655 - recall_1: 0.5299 - val_loss: 0.6975 - val_accuracy: 0.4490 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 1.2500e-05\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.4963 - precision_1: 0.5591 - recall_1: 0.4849Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.69707\n",
      "198/198 [==============================] - 10s 51ms/step - loss: 0.6124 - accuracy: 0.4963 - precision_1: 0.5591 - recall_1: 0.4849 - val_loss: 0.6971 - val_accuracy: 0.5510 - val_precision_1: 0.5510 - val_recall_1: 1.0000 - lr: 6.2500e-06\n",
      "Epoch 32: early stopping\n",
      "\n",
      "Evaluating model...\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.6973 - accuracy: 0.5410 - precision_1: 0.5410 - recall_1: 1.0000\n",
      "Test Loss: 0.6973\n",
      "Test Accuracy: 0.5410\n",
      "Test Precision: 0.5410\n",
      "Test Recall: 1.0000\n",
      "Test F1-Score: 0.7021\n",
      "\n",
      "Evaluating with raw predictions...\n",
      "37/37 [==============================] - 7s 15ms/step\n",
      "Sklearn Precision: 0.5410\n",
      "Sklearn Recall: 1.0000\n",
      "Sklearn F1-Score: 0.7021\n"
     ]
    }
   ],
   "source": [
    "model, history = train_and_evaluate_model(train_data, test_data, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c2ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
